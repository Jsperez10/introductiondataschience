---
output:
  html_document
---

# Principal Components Analysis

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
```

Here we will take all that we've learned about Text as Data and the theory of unsupervised learning to solve a classic problem -- how to identify the author of a text.


### 1. Reading in the files
```{r}
require(quanteda, warn.conflicts = FALSE, quietly = TRUE)

require(readtext)
myCorpus <- corpus(readtext("dickens_austen/*.txt",docvarsfrom = "filenames", dvsep = "_", 
                 docvarnames = c("author", "title")))
summary(myCorpus)
```

```{r}
require(sophistication)
corpus_sentences_browse(myCorpus)
```

### 2. Dividing texts into snippets
```{r}
austen_corpus<-corpus_subset(myCorpus, author == "austen")
dickens_corpus<-corpus_subset(myCorpus, author == "dickens")
mystery_corpus<-corpus_subset(myCorpus, author == "mystery")



austen<-tokens(paste(unlist((austen_corpus$documents$texts)), collapse=' '))
dickens<-tokens(paste(unlist((dickens_corpus$documents$texts)), collapse=' '))
mystery<-tokens(paste(unlist((mystery_corpus$documents$texts)), collapse=' '))


#initialize
austen_snippets<-vector()


##decide on snippet length
snip_length<-1500

## divide up austen texts
for(i in 1:ceiling(length(austen$text1)/snip_length)){
  index<-(i-1)*snip_length + 1
  # create appropriate length snippet
  austen_snippets[i]<-paste(austen$text1[index:(index+snip_length)],sep="", collapse=" ")
}


#initialize
dickens_snippets<-vector() 

## divide up dickens texts
for(i in 1:ceiling(length(dickens$text1)/snip_length)){
  index<-(i-1)*snip_length + 1
  # create appropriate length snippet
  dickens_snippets[i]<-paste(dickens$text1[index:(index+snip_length)],sep="", collapse=" ")
}


#initialize
mystery_snippets<-vector()


## divide up mystery text
for(i in 1:ceiling(ntoken(mystery)/snip_length)){
  index<-(i-1)*snip_length + 1
  # create appropriate length snippet
  mystery_snippets[i]<-paste(mystery$text1[index:(index+snip_length)],sep="", collapse=" ")
}

##combine the snippets
snippets<-c(austen_snippets,dickens_snippets)

#create a labeled vector
authors<-c(rep("austen", length(austen_snippets)), rep("dickens", length(dickens_snippets)))

```

### 3. create DFM of just function words
```{r}
###list function words--taken from Peng & Hengartner
function_words<-c("a", "been", "had", "its", "one", "the", "were", "all", "but", "has", "may", "only", "their", "what",
                  "also", "by", "have", "more", "or", "then", "when", "an", "can", "her", "must", "our", "there", "which",
                  "and", "do", "his", "my", "should", "things", "who",  "any", "down", "if", "no", "so", "this", "will",  
                  "are", "even", "in", "not", "some", "to", "with",  "as", "every", "into", "now", "such", "up", "would",
                  "at", "for", "is", "of", "than", "upon", "your","be", "from", "it", "on", "that", "was")


##Create DFMs of just the function words

snippets_dfm<-dfm(snippets, select = function_words)

mystery_dfm<-dfm(mystery_snippets, select = function_words)
```




### 3. Run PCA
```{r}
###run PCA

snippets_pca<-prcomp(snippets_dfm, center=TRUE, scale.=TRUE)

#snippets_pca<-prcomp(snippets_dfm)

##examine number of components

plot(snippets_pca, type = "l")

##packages for visualization--code taken from http://www.r-bloggers.com/computing-and-visualizing-pca-in-r/


library(ggbiplot)


g <- ggbiplot(snippets_pca, obs.scale = 1, var.scale = 1, 
              groups = authors)
g<- g + theme(legend.direction = 'horizontal', 
              legend.position = 'top')
g
```




### 4. Predict the identity of the mystery book
```{r}

##Predict 
predicted<-predict(snippets_pca, newdata=mystery_dfm)


##Fisher's linear discrimination rule: choose the group that has a closer group mean; just 2 dimensions

#find the mean of the first two PCs 
austen_pc1_mean<-mean(snippets_pca$x[1:length(austen_snippets),1])
austen_pc2_mean<-mean(snippets_pca$x[1:length(austen_snippets),2])
austen_mean<-c(austen_pc1_mean, austen_pc2_mean)


dickens_pc1_mean<-mean(snippets_pca$x[length(austen_snippets):length(snippets),1])
dickens_pc2_mean<-mean(snippets_pca$x[length(austen_snippets):length(snippets),2])
dickens_mean<-c(dickens_pc1_mean, dickens_pc2_mean)


mystery_pc1_mean<-mean(predicted[,1])
mystery_pc2_mean<-mean(predicted[,2])
mystery_mean<-c(mystery_pc1_mean, mystery_pc2_mean)




#calculate the distances
austen_distance<-dist(rbind(austen_mean, mystery_mean))
dickens_distance<-dist(rbind(dickens_mean, mystery_mean))
austen_distance
dickens_distance
```


###It's Austen!

###how else might we do this? 




### k nearest neighbors! 

### 5. Run KNN
```{r}
#install.packages("class")

library(class)

?knn




knn_1<-knn(train=snippets_dfm, test = mystery_dfm, cl = authors, k=1 )
knn_1
```

### 6. Try different values for K
```{r}

knn_3<-knn(train=snippets_dfm, test = mystery_dfm, cl = authors, k=3 )

knn_10<-knn(train=snippets_dfm, test = mystery_dfm, cl = authors, k=10 )


knn_3
knn_10
```


