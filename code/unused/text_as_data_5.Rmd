---
output:
  html_document
---

# Descriptive Analysis of Texts

### Adapted from code by Ken Benoit


```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
```
quateda has a number of descriptive statistics available for reporting on texts.  The **simplest of these** is through the `summary()` method:
```{r}
require(quanteda)
txt <- c(sent1 = "This is an example of the summary method for character objects.",
         sent2 = "The cat in the hat swung the bat.")
summary(txt)
```

This also works for corpus objects:
```{r}
summary(corpus(data_char_ukimmig2010, notes = "Created as a demo."))
```

To access the **syllables** of a text, we use `syllables()`:
```{r}
nsyllable(c("Superman.", "supercalifragilisticexpialidocious", "The cat in the hat."))
```


We can **identify documents and terms that are similar to one another**, using `similarity()`:
```{r}
## Presidential Inaugural Address Corpus
presDfm <- corpus_subset(data_corpus_inaugural, Year > 1980) %>%
    dfm(remove = stopwords("english"), remove_punct = TRUE)
# compute some document similarities
textstat_simil(presDfm, "1985-Reagan")
textstat_simil(presDfm, c("2009-Obama", "2013-Obama"), method = "cosine")
textstat_dist(presDfm, c("2009-Obama", "2013-Obama"), method = "canberra")
textstat_dist(presDfm, c("2009-Obama", "2013-Obama"), method = "ejaccard")

# compute some term similarities
lapply(as.list(textstat_simil(presDfm, c("fair", "health", "terror"), margin = "features", method = "cosine")), 
       head, n = 10)
```

And this can be used for **clustering documents**:
```{r, fig.height=6, fig.width=10}
data(data_corpus_sotu, package = "quanteda.corpora")
presDfm <- dfm(corpus_subset(data_corpus_sotu, Date > "1990-01-01"), stem = TRUE,
               remove = c(stopwords("english"), "applause"), remove_punct = TRUE)
presDfm <- dfm_trim(presDfm, min_termfreq = 5, min_docfreq = 3)
# hierarchical clustering - get distances on normalized dfm
presDistMat <- dist(as.matrix(dfm_weight(presDfm, "relFreq")))
# hiarchical clustering the distance object
presCluster <- hclust(presDistMat)
# label with document names
presCluster$labels <- docnames(presDfm)
# plot as a dendrogram
plot(presCluster)
```

Or we could look at **term clustering** instead:
```{r, fig.height=8, fig.width=12}
# word dendrogram with tf-idf weighting
wordDfm <- dfm_sort(dfm_tfidf(presDfm))
wordDfm <- t(wordDfm)[1:100,]  # because transposed
wordDistMat <- dist(wordDfm)
wordCluster <- hclust(wordDistMat)
plot(wordCluster, xlab="", main="tf-idf Frequency weighting")
```

